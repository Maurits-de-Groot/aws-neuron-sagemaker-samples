{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4feac2fd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Fine tuning BERT base model from HuggingFace on Amazon SageMaker\n",
    "\n",
    "## Overview\n",
    "\n",
    "This tutotial uses the Hugging Face transformers and datasets libraries with Amazon SageMaker to fine-tune a pre-trained BERT base model on binary text classification.\n",
    "\n",
    "A [pre-trained model](https://huggingface.co/bert-base-uncased) is available in the transformers library from Hugging Face. Youâ€™ll be fine-tuning this pre-trained model using the [Amazon Plarity dataset](https://huggingface.co/datasets/amazon_polarity) which classify the content into either positive or negative feedback.\n",
    "\n",
    "This Jupyter Notebook can run either on SageMaker notebook instance or SageMaker Studio Notebook.\n",
    "\n",
    "You can set up your SageMaker Notebook instance by following the [Get Started with Amazon SageMaker Notebook Instances](https://docs.aws.amazon.com/sagemaker/latest/dg/gs-console.html) or SageMaker Studio Notebook by following the [Use Amazon SageMaker Studio Notebooks](https://docs.aws.amazon.com/sagemaker/latest/dg/notebooks.html)\n",
    "\n",
    "The notebook was tested on a `ml.t3.medium` SageMaker Studio Notebook with `Data Science` image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4170f6bc",
   "metadata": {},
   "source": [
    "## Development Environment and Permissions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602b1ff5",
   "metadata": {},
   "source": [
    "For SageMaker Studio, please make sure ipywidgets is installed and restart the kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc54f106",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "import IPython\n",
    "import sys\n",
    "\n",
    "!{sys.executable} -m pip install ipywidgets\n",
    "IPython.Application.instance().kernel.do_shutdown(True)  # has to restart kernel so changes are used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e17d62",
   "metadata": {},
   "source": [
    "This tutorial requires the following pip packages:\n",
    "  + transformers\n",
    "  + datasets\n",
    "\n",
    "Please make sure SageMaker version is 2.146.0 or byond."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1762d47-068b-4921-bfa2-b64f5c361ea7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!{sys.executable} -m pip install --upgrade pip\n",
    "!{sys.executable} -m pip install --upgrade --no-cache-dir sagemaker\n",
    "!{sys.executable} -m pip install --upgrade --no-cache-dir torch==1.13.1\n",
    "!{sys.executable} -m pip install --upgrade --no-cache-dir transformers==4.27.4 datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe76393a-dd21-439d-9df4-fb8807cdd9be",
   "metadata": {},
   "source": [
    "After these pip install commands in a notebook, make sure to restart your kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4b0e3f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorch\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de3bc86",
   "metadata": {},
   "source": [
    "### Create Sagemaker session\n",
    "Next, create a SageMaker session and define an execution role. Default role should suffice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3492c0c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sess = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "sess_bucket = sess.default_bucket()\n",
    "region = sess.boto_region_name\n",
    "\n",
    "print(f'sagemaker role arn: {role}')\n",
    "print(f'sagemaker bucket: {sess_bucket}')\n",
    "print(f'sagemaker session region: {region}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16196f63",
   "metadata": {},
   "source": [
    "## Dataset preparation\n",
    "For this example, we will use the `datasets` library to download and preprocess the `amazon_polarity` dataset from Hugging Face.\n",
    "\n",
    "https://huggingface.co/datasets/amazon_polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727cd45f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pre-trained model used\n",
    "model_name = 'bert-base-uncased'\n",
    "\n",
    "# dataset used\n",
    "dataset_name = 'amazon_polarity'\n",
    "\n",
    "# s3 key prefix\n",
    "s3_prefix = 'bert-base-uncased-amazon-polarity'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d07082",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prepare dataset\n",
    "train_dataset, test_dataset = load_dataset(dataset_name, split=['train', 'test'])\n",
    "\n",
    "# Reduced the dataset for testing purpose\n",
    "train_dataset = train_dataset.shuffle().select(range(4000))\n",
    "test_dataset = test_dataset.shuffle().select(range(156))\n",
    "\n",
    "# Let's take a look one example from the training dataset.\n",
    "index = 0\n",
    "print(train_dataset[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f221da-8b59-4925-a9e4-48a136284661",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Let's take a look one example to understand how original sentence is tokeninzed and encoded.\n",
    "print('Tokenize:', tokenizer.tokenize(train_dataset['content'][index]))\n",
    "print('Encode:', tokenizer.encode(train_dataset['content'][index]))\n",
    "\n",
    "# Helper function to get the content to tokenize\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['content'], padding='max_length', max_length=128, truncation=True)\n",
    "\n",
    "# Tokenize\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Set the format to PyTorch\n",
    "train_dataset = train_dataset.rename_column(\"label\", \"labels\")\n",
    "train_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "test_dataset = test_dataset.rename_column(\"label\", \"labels\")\n",
    "test_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a28235a",
   "metadata": {},
   "source": [
    "### Uploading dataset to S3 Bucket\n",
    "After we processed the dataset we are going to use the new FileSystem integration to upload our dataset to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c890fc66",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets.filesystems import S3FileSystem\n",
    "\n",
    "s3 = S3FileSystem()  \n",
    "\n",
    "# save dataset to s3\n",
    "training_input_path = f's3://{sess_bucket}/{s3_prefix}/{dataset_name}/train'\n",
    "train_dataset.save_to_disk(training_input_path, fs=s3)\n",
    "\n",
    "test_input_path = f's3://{sess_bucket}/{s3_prefix}/{dataset_name}/test'\n",
    "test_dataset.save_to_disk(test_input_path, fs=s3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38ffce8",
   "metadata": {},
   "source": [
    "## Leveraging Neuron Persistent Cache\n",
    "PyTorch Neuron performs just-in-time compilation of graphs during execution. At every step if the traced graph varies from the previous executions, it is compiled by the neuron compiler.\n",
    "The compilation result can be saved in on-disk [Neuron Persistent Cache](https://awsdocs-neuron.readthedocs-hosted.com/en/latest/general/arch/neuron-features/neuron-caching.html) to avoid compilations across training runs. In order to keep such cache across SageMaker traing jobs, we add the mechanism to restore the cache from S3 at the begging of the training job and then store back to S3 at the end of the training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06df501f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import tarfile\n",
    "\n",
    "# If neuron compile cache does not exist in S3, create dummy file.\n",
    "if not sess.list_s3_files(sess_bucket, f'{s3_prefix}/neuron-compile-cache.tar.gz'):\n",
    "    pathlib.Path('./dummy').touch()\n",
    "    with tarfile.open('neuron-compile-cache.tar.gz', 'w:gz') as t:\n",
    "        t.add('dummy')\n",
    "    sess.upload_data('./neuron-compile-cache.tar.gz', sess_bucket, s3_prefix)\n",
    "\n",
    "s3_prefix_path = f's3://{sess_bucket}/{s3_prefix}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44511ae",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Fine-tuning & starting Sagemaker Training Job\n",
    "In order to create a sagemaker training job we use [PyTorch Estimator](https://sagemaker.readthedocs.io/en/stable/frameworks/pytorch/using_pytorch.html#train-a-model-with-pytorch). The Estimator handles end-to-end Amazon SageMaker training and deployment tasks. In a Estimator we define, which fine-tuning script should be used as `entry_point`, which `instance_type` should be used, which `hyperparameters` are passed in .....\n",
    "\n",
    "Note) SageMaker support for EC2 Trn1 instance is currently available only for PyTorch Estimator. HuggingFace Estimator will be available in future release."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f590e97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hyperparameters, which are passed into the training job\n",
    "hyperparameters={'epochs': 10,               # number of training epochs\n",
    "                 'train_batch_size': 8,      # batch size for training\n",
    "                 'eval_batch_size': 8,       # batch size for evaluation\n",
    "                 'learning_rate': 5e-5,      # learning rate used during training\n",
    "                 'model_name':model_name,    # pre-trained model\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfe2846-7c57-49bc-9f4b-f5d3d3327a2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://github.com/aws/deep-learning-containers/blob/master/available_images.md#neuron-containers\n",
    "train_image_name=\"pytorch-training-neuronx\"\n",
    "image_tag=\"1.13.1-neuronx-py310-sdk2.12.0-ubuntu20.04\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de7055a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pt_estimator = PyTorch(\n",
    "    entry_point='train.py',\n",
    "    source_dir='scripts',\n",
    "    image_uri=f\"763104351884.dkr.ecr.{region}.amazonaws.com/{train_image_name}:{image_tag}\",\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.trn1.2xlarge',\n",
    "    base_job_name=s3_prefix,\n",
    "    hyperparameters=hyperparameters,\n",
    "\n",
    "    distribution={\n",
    "        'torch_distributed': {\n",
    "            'enabled': True\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c861f6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pygmentize ./scripts/train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5911250e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define a data input dictonary with our uploaded s3 uris\n",
    "data = {\n",
    "    'train': training_input_path,\n",
    "    'test': test_input_path,\n",
    "    's3_prefix': s3_prefix_path  # To restore Neuron Persistent Cache archive from S3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fe435f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# starting the train job with our uploaded datasets as input\n",
    "pt_estimator.fit(data, wait=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d3227d57-9648-4537-8fcf-29cec80d3043",
   "metadata": {},
   "source": [
    "Training job takes about 23~25 minutes without compile cache, 10~12 minutes with compile cache."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92abb2f",
   "metadata": {},
   "source": [
    "### Backup Neuron Persistent Cache into S3 for the following training jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c911a88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TrainingJobName = pt_estimator.latest_training_job.describe()['TrainingJobName']\n",
    "\n",
    "sess.download_data('./', sess_bucket, f'{TrainingJobName}/output/output.tar.gz')\n",
    "\n",
    "import tarfile\n",
    "with tarfile.open('output.tar.gz', 'r') as t:\n",
    "    t.extractall('./output/')\n",
    "\n",
    "with tarfile.open('neuron-compile-cache.tar.gz', 'w:gz') as t:\n",
    "    t.add('./output/', arcname='./')\n",
    "\n",
    "sess.upload_data('./neuron-compile-cache.tar.gz', sess_bucket, s3_prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d7e92f",
   "metadata": {},
   "source": [
    "## Quick check the prediction result.\n",
    "Let's quickly check to see if the fine-tuned model produces the expected prediction results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7d23c8-97f5-49b0-ba1f-a6b183b8fc55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sess.download_data('./', sess_bucket, f'{TrainingJobName}/output/model.tar.gz')\n",
    "    \n",
    "with tarfile.open('model.tar.gz', 'r') as t:\n",
    "    t.extractall('./model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e99ecfd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline('text-classification', model = './model/')\n",
    "\n",
    "print(classifier('This is the most amazing product I have ever seen. I love it.'))\n",
    "print(classifier('big disappointment. I will not use it.'))\n",
    "print(classifier('Wonderful product. I will let my friends know.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61eb616",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Congratulation ! You can see the expected results !"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
